{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa467b9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# GPU arrays\n",
    "\n",
    "pyClesperanto is an image processing library. This means that it will apply operations on data which are commonly stored using the numpy library in Python. However, numpy arrays are stored for CPU processing, they are not directly accessible by the GPU. If we want to apply GPU-accelerate operation on arrays, we need to send the data into the GPUs memory.\n",
    "\n",
    "For this, the library provides an array class called `OCLArray` which offer a similar interface as numpy arrays and allows to hold data in the GPU memory.\n",
    "\n",
    "\n",
    "We will base the data manipulation on three operations:\n",
    "- `create` a memory space on the device\n",
    "- `push` data into the device\n",
    "- `pull` the data from the device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa560bbe-ce20-4a04-97ec-52a67bc4cab0",
   "metadata": {},
   "source": [
    "### Create \n",
    "\n",
    "We `create` a memory space on the device. The create array is empty by default (all value to 0).  \n",
    "The only mandatory argument is its shape, following the coordinate standard (z,y,x). \n",
    "\n",
    "It is also possible to pass a `dtype` argument to specify the data type to be stored. By default, `float32` is used.\n",
    "\n",
    "Note: float64 type are not compatible for hardware reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1922cc9a-556c-414e-ade1-be8c517c209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyclesperanto_prototype._tier0._pycl.OCLArray'> (24, 24) float32\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import pyclesperanto_prototype as cle\n",
    "import numpy as np\n",
    "\n",
    "new_gpu_array = cle.create((24,24))\n",
    "print(type(new_gpu_array), new_gpu_array.shape, new_gpu_array.dtype)\n",
    "print(new_gpu_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80dfaa",
   "metadata": {},
   "source": [
    "Here, `new_gpu_array` is a class holding information and pointer to the GPU memory. It is not a numpy array although it behave very similarly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0464a-4b11-4baa-a941-73ffcfe9e707",
   "metadata": {},
   "source": [
    "### Push \n",
    "\n",
    "If we already have a data array, an image for example, then we simply have to `push` it on the device. \n",
    "This is in fact two operation, a `create` space memory, and a `copy` the memory into the created space on the device.  \n",
    "\n",
    "Let's load some data (some blobs for example) and store into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d22fec74-1818-42c9-9205-b61cca9da6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (24, 24) float64\n"
     ]
    }
   ],
   "source": [
    "array = np.ones((24,24))\n",
    "print(type(array), array.shape, array.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df4b5c9-5f4b-4baf-97e9-4cb99d5eeaf1",
   "metadata": {},
   "source": [
    "We can now push it to the device using the `push` method. Here we will use the same `dtype` and `shape` provided by the numpy array to define the array on the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3af2b33-b375-44b0-906e-2c323baff5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyclesperanto_prototype._tier0._pycl.OCLArray'> (24, 24) float32\n"
     ]
    }
   ],
   "source": [
    "gpu_array = cle.push(array)\n",
    "print(type(gpu_array), gpu_array.shape, gpu_array.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ae9be",
   "metadata": {},
   "source": [
    "We have now pushed the array image to the GPU memory. Ready to be used in the librairy. \n",
    "\n",
    "Note: is you have a NVIDIA GPU, you can use the system command `nvidia-smi` to see the memory usage of your GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8df9df3-de81-420d-8013-f1ee4b67df41",
   "metadata": {},
   "source": [
    "### Pull \n",
    "\n",
    "`pull` is the exact inverse of the `push`. Here  we want to read back the memory located on the device.\n",
    "\n",
    "Similarly to the `push` that read the information from the numpy metadata, we do the same for the pull. We read the metadata of our gpu data array and create a corresponding numpy array, and store the data in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4994d949-f2fd-4311-b1e2-544586d323a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (24, 24) float32\n"
     ]
    }
   ],
   "source": [
    "read_array = cle.pull(gpu_array)\n",
    "print(type(read_array), read_array.shape, read_array.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d101bf91-cc47-4e2c-b6f8-ad796264c65d",
   "metadata": {},
   "source": [
    "Here we just pull the array we pushed earlier. They should be the same as we did not do any processing on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d1fce1-190d-4e59-92cc-56b5caed97c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.array_equal(array, read_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d749a",
   "metadata": {},
   "source": [
    "Data located on the GPU memory are not readable by classical Python functions or numpy. We always need to `pull` them back from the GPU and then we can read them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de00041",
   "metadata": {},
   "source": [
    "## Exercise : push and pull images\n",
    "\n",
    "Let's load our favorite image into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1772df83",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imread' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m array \u001b[38;5;241m=\u001b[39m \u001b[43mimread\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/blobs.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(array), array\u001b[38;5;241m.\u001b[39mshape, array\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m      3\u001b[0m _ \u001b[38;5;241m=\u001b[39m imshow(array)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imread' is not defined"
     ]
    }
   ],
   "source": [
    "array = imread(\"../../data/blobs.tif\")\n",
    "print(type(array), array.shape, array.dtype)\n",
    "_ = imshow(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5045fb",
   "metadata": {},
   "source": [
    "Using `push` and `pull`, move the image into the GPU memory and read it back. What can you observe when looking at the metadata of the image? Is the data copied back is identical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85d0a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94f22f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NVIDIA GeForce RTX 2080 SUPER on Platform: NVIDIA CUDA (1 refs)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyclesperanto_prototype as cle\n",
    "import numpy as np\n",
    "from skimage.io import imread, imshow\n",
    "cle.select_device('TX')  # TODO: change to your GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762105aa",
   "metadata": {},
   "source": [
    "# GPU memory management\n",
    "\n",
    "The majority of errors you may encounters will be related to overusage of the GPU memory. If you have a GPU with 8 GB of memory, your largest processing capacity (for basic operations) might be around 2 GB. This is because the GPU needs to store the input and output images in memory. If you have a GPU with 16 GB of memory, you can process images up to 4 GB in size. Etc.\n",
    "\n",
    "However, this capacity drops again when you are applying more advance pipeline or algorithm as we will see later on.\n",
    "\n",
    "For NVIDIA users, the command `nvidia-smi` will give you an overview of the memory usage of your GPU, and it is possible to use the keyword `del` to delete a variable from the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0224de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory.used [MiB]\n",
      "1724 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=memory.used --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "986c2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.random.random((1024, 1024, 100))\n",
    "blurred = cle.gaussian_blur(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a382f7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory.used [MiB]\n",
      "2130 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=memory.used --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2434ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e24a0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory.used [MiB]\n",
      "1731 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=memory.used --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b26eeaa",
   "metadata": {},
   "source": [
    "Be aware though that if you delete data while still being needed by the GPU in an other process, you may create errors. To be handle with care!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4571ff7c",
   "metadata": {},
   "source": [
    "## Exercise 2: push the largest image you can on your device\n",
    "\n",
    "GPU memory is limited. You do not have as much space as if you were using your computer RAM. It is important to grasp the size of the images you can push on your device. As well as the memory needed to apply complex process operation on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af3a15d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
